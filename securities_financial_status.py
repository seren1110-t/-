# -*- coding: utf-8 -*-
"""securities_financial_status

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14okqLVHz70Wn2kjmjwiIeu8eHPE3-ccX
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime
import time

def get_kospi_tickers():
    stocks = []
    headers = {'User-Agent': 'Mozilla/5.0'}
    for page in range(1, 21):  # 코스피 시가총액 20페이지 전부 크롤링 (약 1000개 종목)
        url = f"https://finance.naver.com/sise/sise_market_sum.naver?sosok=0&page={page}"
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, "html.parser")
        rows = soup.select("table.type_2 tr")

        for row in rows:
            a_tag = row.select_one("a.tltle")
            if a_tag:
                name = a_tag.text.strip()
                href = a_tag['href']
                code = href.split('code=')[-1]
                stocks.append({"종목명": name, "종목코드": code})
    return pd.DataFrame(stocks)

def get_stock_report(code):
    headers = {'User-Agent': 'Mozilla/5.0'}
    url = f"https://finance.naver.com/item/main.naver?code={code}"
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, "html.parser")

    today = datetime.now().strftime("%Y-%m-%d")

    try:
        name = soup.select_one("div.wrap_company h2 a").text.strip()
    except:
        name = None

    try:
        current_price = soup.select_one("p.no_today .blind").text.strip().replace(',', '')
    except:
        current_price = None

    roe_최근, debt_최근, reserve_최근, per_최근, pbr_최근 = [None]*5
    roe_전기, debt_전기, reserve_전기, per_전기, pbr_전기 = [None]*5
    sales_최근, operating_최근, net_income_최근 = [None]*3
    sales_전기, operating_전기, net_income_전기 = [None]*3

    try:
        table = soup.select_one("#content > div.section.cop_analysis > div.sub_section > table")
        rows = table.select("tbody tr")

        def get_text(row_idx, td_idx):
            try:
                return rows[row_idx].select("td")[td_idx].text.strip()
            except:
                return None

        roe_최근, roe_전기 = get_text(5, 8), get_text(5, 7)
        debt_최근, debt_전기 = get_text(6, 8), get_text(6, 7)
        reserve_최근, reserve_전기 = get_text(8, 8), get_text(8, 7)
        per_최근, per_전기 = get_text(10, 8), get_text(10, 7)
        pbr_최근, pbr_전기 = get_text(12, 8), get_text(12, 7)

        sales_최근, sales_전기 = get_text(0, 8), get_text(0, 7)
        operating_최근, operating_전기 = get_text(1, 8), get_text(1, 7)
        net_income_최근, net_income_전기 = get_text(2, 8), get_text(2, 7)

    except Exception as e:
        print(f"[{code}] 재무지표 추출 오류: {e}")

    # -------------------- 최신 뉴스 --------------------
    latest_news = []
    try:
        base_url = "https://finance.naver.com"
        news_items = soup.select(
            "#content > div.section.new_bbs > div.sub_section.news_section > ul:nth-child(2) > li > span > a"
        )
        for item in news_items[:3]:
            href = item.get("href")
            if href and href.startswith("/item/news_read.naver"):
                full_url = base_url + href
                latest_news.append(full_url)
    except Exception as e:
        print(f"[{code}] 뉴스 추출 오류: {e}")




    return {
        "종목명": name,
        "티커": code,
        "작성일자": today,
        "현재가": current_price,

        # 재무지표 (최근/전기)
        "ROE_최근": roe_최근, "ROE_전기": roe_전기,
        "부채비율_최근": debt_최근, "부채비율_전기": debt_전기,
        "유보율_최근": reserve_최근, "유보율_전기": reserve_전기,
        "PER_최근": per_최근, "PER_전기": per_전기,
        "PBR_최근": pbr_최근, "PBR_전기": pbr_전기,

        # 실적 (최근/전기)
        "매출액_최근": sales_최근, "매출액_전기": sales_전기,
        "영업이익_최근": operating_최근, "영업이익_전기": operating_전기,
        "순이익_최근": net_income_최근, "순이익_전기": net_income_전기,

        # 최신 뉴스
        "최신뉴스": latest_news
    }

def collect_kospi_reports(limit=None):
    tickers_df = get_kospi_tickers()
    if limit:
        tickers_df = tickers_df.head(limit)

    reports = []
    total = len(tickers_df)
    for idx, row in tickers_df.iterrows():
        code = row['종목코드']
        report = get_stock_report(code)
        reports.append(report)
        print(f"[{idx+1}/{total}] {report['종목명']}({code}) 수집 완료")
        time.sleep(0.5)

    return pd.DataFrame(reports)

# 전종목 모두 수집
df = collect_kospi_reports(limit=1)

df  = df.dropna()



import pandas as pd
from pykrx import stock
from datetime import datetime, timedelta

# 조회 날짜 범위 설정 (최근 1년)
end_date = datetime.today()
start_date = end_date - timedelta(days=365)

# 날짜 리스트 생성 (영업일 기준)
date_list = stock.get_market_ohlcv_by_date(start_date.strftime("%Y%m%d"),
                                           end_date.strftime("%Y%m%d"),
                                           "005930").index.strftime("%Y%m%d").tolist()

# 결과 저장용 데이터프레임 초기화
price_df = pd.DataFrame()

# 날짜별로 전체 종목 종가 받아오기
for date in date_list:
    try:
        daily_prices = stock.get_market_ohlcv_by_ticker(date, market="ALL")[["종가"]]
        daily_prices.columns = [date]
        price_df = pd.concat([price_df, daily_prices], axis=1)
    except:
        print(f"{date} 데이터 실패")
        continue

merged_df = price_df.reset_index().merge(df, on="티커", how="inner")

merged_df.최신뉴스[0]

merged_df

import sqlite3
import os
import subprocess

db_path = "financial_data.db"
table_name = "merged_financials"

# list 타입이 있다면 str로 변환
merged_df = merged_df.applymap(lambda x: str(x) if isinstance(x, list) else x)

# SQLite 데이터베이스 연결 및 저장
conn = sqlite3.connect(db_path)
merged_df.to_sql(table_name, conn, if_exists="replace", index=False)
conn.close()

# Git 자동 커밋 및 푸시
try:
    # 1. git add
    subprocess.run(["git", "add", db_path], check=True)

    # 2. git commit
    subprocess.run(["git", "commit", "-m", f"Update {db_path}"], check=True)

    # 3. git push
    subprocess.run(["git", "push"], check=True)
    print("✅ Git push 완료")

except subprocess.CalledProcessError as e:
    print("❌ Git push 실패:", e)
